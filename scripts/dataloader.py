
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/DataLoader.ipynb
from collections.abc import Iterable
from collections import OrderedDict
from pathlib import Path
import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import random
from functools import partial

from utils import listify, compose, setify

def _get_files(path, files, extensions=None):
    p = Path(path)
    res = [p/f for f in files if not f.startswith('.') and (not extensions or (f"{f.split('.')[-1].lower()}" in extensions))]
    return res



def get_MRI_slices(base_path, base_component, extensions, include=None):
    base_path = Path(base_path)
    extensions = setify(extensions)
    extensions = {o.lower() for o in extensions}
    items = []
    for i, (path, dirs, files) in enumerate(os.walk(base_path)):
        if include is not None and i==0: dirs[:] = [o for o in dirs if o in include]
        if base_component in dirs: dirs[:] = [base_component]
        items += _get_files(path, files, extensions)
    return items




def get_related_filenames(path, components, num_sublevels = 2):
    path = Path(path)
    basepath, filename = path, path.name
    for _ in range(num_sublevels): basepath = basepath.parent
    return [basepath/component/filename for component in components]

class Transform():
    _order = 0

class NormalizeMRI(Transform):
    _order = 5
    def __init__(self, il):
        n=len(il)


class ToTensor(Transform):
    _order = 10
    def __call__(self, data):
        if isinstance(data, torch.Tensor): return data
        return torch.tensor(data)

class ToFloat(Transform):
    _order = 20
    def __call__(self, data):
        return data.float()


class MRIObject():
    def __init__(self, fn, components, tfms=None):
        self.fn, self.tfms = fn, listify(tfms)
        self.components = components
        self.data = self._load_files()
    def _show(self, img):
        if isinstance(img, torch.Tensor): img = np.array(img)
        if img.ndim == 3: img = np.transpose(img, (1,2,0))
        if img.shape[2]==1: img=img[:,:,0]
        img-=np.min(img, axis=(0,1), keepdims=True)
        img/=np.max(img, axis=(0,1), keepdims=True)
        plt.imshow(img)
        plt.axis('off')
        plt.show()
    def __repr__(self):
        channels = self.data.shape[0]
        display_channels = slice(0,1 if channels==2 else 3)
        message = "Input contains more than 3 channels, displaying the first three 3:\n" if channels>3 else "\n"
        message += f"Components: {self.components[display_channels]}"
        self._show(self.data[display_channels,...])
        return message
    def get_data(self): self.data
    def get_slice(self, component):
        if component in self.raw_data: return self.raw_data[component]
        return None
    def _load_files(self):
        self.individual_filepaths = get_related_filenames(self.fn, self.components, 2)
        self.individual_files = {c:np.load(fp) for c,fp in zip(self.components, self.individual_filepaths)}
        self.raw_data = np.concatenate([np.load(fp) for fp in self.individual_filepaths])
        return self.process(self.raw_data)
    def process(self, data): return compose(data, self.tfms)
    @property
    def shape(self): return self.data.shape

class ListContainer():
    def __init__(self, items): self.items = items
    def __getitem__(self, idx):
        try: return self.items[idx]
        except TypeError:
            if isinstance(idx[0], bool):
                assert len(idx)==len(self.items)
                return [o for o,i in zip(self.items, idx) if i]
            else: return [self.items[i] for i in idx]
    def __len__(self): return len(self.items)
    def __iter__(self): return iter(self.items)
    def __setitem__(self, i, o): self.items[i] = o
    def __delitem__(self, i): del self.items[i]
    def __repr__(self):
        res = f"{self.__class__.__name__} ({len(self)} items)\n{self.items[:10]}"
        if len(self)>10: res = res[:-1]+'...]'
        return res

class ItemList(ListContainer):
    def __init__(self, items, path='.', tfms=None):
        super().__init__(items)
        self.path, self.tfms = path, listify(tfms)
    def new(self, items, cls = None, **kwargs):
        if cls is None: cls=self.__class__
        return cls(items, path=self.path, tfms=self.tfms, **kwargs)
    def __repr__(self): return f"{super().__repr__()}\nPath: {self.path}"
    def get(self, o): return o  #Overwrite in subclass
    def get_and_process(self, o): return compose(self.get(o), self.tfms)
    def __getitem__(self, idxs):
        items = super().__getitem__(idxs) #return either an item of a list of raw inputs
        if isinstance(items, list): return [self.get_and_process(o) for o in items]
        else: return self.get_and_process(items)


class MRIImageList(ItemList):
    @classmethod
    def from_files(cls, path, components=['mean'], extensions=None, include=None, img_tfms=None, **kwargs):
        items = get_MRI_slices(path, components[0], extensions)
        return cls(items, path, components, img_tfms, **kwargs)

    def __init__(self, items, path, components, img_tfms=None, **kwargs):
        super().__init__(items, path, **kwargs)
        self.components = self.set_components(components)
        self.img_tfms=listify(img_tfms)

    def get(self, fn): return MRIObject(fn, self.components, self.img_tfms)
    def __repr__(self): return f"{super().__repr__()}\nComponents: {self.components}"
    def new(self, items, **kwargs):
        return super().new(items, components = self.components, img_tfms = self.img_tfms, **kwargs)
    def __add__(self, n): return np.add()
    def set_components(self, components): return listify(components)



def get_user(path, sublevels=2):
    path = Path(path)
    for _ in range(sublevels): path = path.parent
    return path.name

def split_by_user(items, train_users, sublevels=2):
    mask = [get_user(i) in train_users for i in items]
    train = [o for o,m in zip(items, mask) if m==True]
    valid = [o for o,m in zip(items, mask) if m==False]
    return train, valid


####  ©nandinee
def split_by_valid_user(items, valid_users):
    mask = [get_user(i) in valid_users for i in items]
    valid = [o for o,m in zip(items, mask) if m==True]
    train = [o for o,m in zip(items, mask) if m==False]
    return train, valid



class SplitData():
    def __init__(self, train, valid):
        self.train = train
        self.valid = valid
    def __getattr__(self, k): return self.train.k
    def __setstate__(self, data): self.__dict__.update(data) #Needed to pickle properly

    @classmethod
    def split_by_rdn_user(cls, il, pct):
        users = list({get_user(fp) for fp in il.items})
        random.shuffle(users)
        train_users = users[:int(len(users)*pct)]
        lists = map(il.new, split_by_user(il.items, train_users))
        return cls(*lists)
    
    ####  ©nandinee
    @classmethod
    def split_by_user_fold(cls, il, valid_users):
        lists = map(il.new, split_by_valid_user(il.items, valid_users))
        return cls(*lists)

    def __repr__(self): return f"Split Data:\nTrain: {self.train}\n\nValid: {self.valid}"

    def to_databunch(self, batch_size = 16):
        dls = get_dataloaders(self.train, self.valid, batch_size, sampler=Sampler, collate_func = collate_mri)
        c_in = self.train.x[0].shape[0]
        c_out = self.train.y[0].shape[0]
        return DataBunch(*dls, c_in, c_out)


def _label_by_func(il, f, cls=ItemList, **kwargs):
    return cls([f(i) for i in il.items], **kwargs)

def relative_labeller(fn, label_folder, base_component):
    """Assumes a path of the form root_path/img_folder/user_id/base_img_component/file
    and changes it to             root_path/gt_folder /user_id/base_gt_component /file
    """
    fn = Path(fn)
    name = fn.name
    user_id = fn.parent.parent.name
    root_path = fn.parent.parent.parent.parent
    return root_path/label_folder/user_id/base_component/name


class LabelledData():
    def process(self, il, proc): return il.new(compose(il.items, proc))
    def __init__(self, x, y, proc_x=None, proc_y=None):
        self.x, self.y = self.process(x, proc_x), self.process(y, proc_y)
        self.proc_x, self.proc_y = proc_x, proc_y

    def __repr__(self): return f"{self.__class__.__name__}\nx:{self.x}\n\ny:{self.y}"
    def __getitem__(self, idx): return self.x[idx], self.y[idx]
    def __len__(self): return len(self.x)

    @classmethod
    def label_from_function(cls, il, label_components, func, label_folder,
                            label_tfms=None, proc_x=None, proc_y=None, **kwargs):
        x = il
        f = partial(relative_labeller, label_folder = label_folder, base_component=label_components[0])
        y = _label_by_func(il, f, cls=MRIImageList, path=il.path.parent/label_folder,
                           img_tfms = label_tfms, components = label_components)
        return cls(x, y, proc_x, proc_y)

def label_by_function(sd, gt_components, func, label_folder, label_tfms=None, proc_x=None, proc_y=None):
    train = LabelledData.label_from_function(sd.train, gt_components, relative_labeller, label_folder, label_tfms)
    valid = LabelledData.label_from_function(sd.valid, gt_components, relative_labeller, label_folder, label_tfms)
    return SplitData(train, valid)


class Sampler():
    def __init__(self, dataset, batch_size, shuffle=False):
        self.n, self.batch_size, self.shuffle = len(dataset), batch_size, shuffle
    def __iter__(self):
        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)
        for i in range(0, self.n, self.batch_size): yield self.idxs[i:i+self.batch_size]



def collate_mri(batch):
    """This collate function assumes a list of MRIObjects arranged as
    [(x1, y1), (x2,y2), ...]
    x,y will each have a shape of            C x W x H
    Outputs xb, yb will have the shape   N x C x W x H
    """
    xs, ys = batch
    xs, ys = [i.data for i in xs], [i.data for i in ys]
    return torch.stack(xs), torch.stack(ys)


def collate_mri(batch):
    """This collate function assumes a list of MRIObjects arranged as
    [(x1, y1), (x2,y2), ...]
    x,y will each have a shape of            C x W x H
    Outputs xb, yb will have the shape   N x C x W x H
    """
    xs, ys = zip(*batch)
    xs, ys = [i.data for i in xs], [i.data for i in ys]
    return torch.stack(xs), torch.stack(ys)



class DataLoader():
    def __init__(self, dataset, batch_size=1, sampler=None, collate_func=collate_mri):
        if sampler is None: sampler = Sampler(dataset, batch_size, shuffle=True)
        assert sampler.batch_size == batch_size, \
                                      f"Batch size mismatch.  DataLoader:{batch_size}, Sampler:{sampler.batch_size}"
        self.dataset, self.batch_size, self.sampler, self.collate_func = dataset, batch_size, sampler, collate_func


    def __iter__(self):
        for idxs in self.sampler:
            self.batch = [self.dataset[idx] for idx in idxs]
            yield self.collate_func(self.batch)

    def custom_batch(self,idxs): return self.collate_func([self.dataset[idx] for idx in idxs])

    def __len__(self):
        i = 0
        for _ in self.sampler: i+=1
        return i

def get_dataloaders(train, valid, bs, sampler=Sampler, collate_func=collate_mri):
    train_sampler = sampler(train, bs, shuffle=True)
    valid_sampler = sampler(valid, bs, shuffle=False)

    train_dl = DataLoader(train, bs, train_sampler, collate_func)
    valid_dl = DataLoader(valid, bs, valid_sampler, collate_func)
    return train_dl, valid_dl


class DataBunch():
    def __init__(self, train_dl, valid_dl, c_in=None, c_out=None):
        self.train_dl, self.valid_dl, self.c_in, self.c_out = train_dl, valid_dl, c_in, c_out

    @property
    def train_ds(self): return self.train_dl.dataset

    @property
    def valid_ds(self): return self.valid_dl.dataset
